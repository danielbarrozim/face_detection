{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "[Face detection](https://en.wikipedia.org/wiki/Face_detection) is a computer technology being used in various applications that identify human faces in digital images.  The purpose of this project is to research face detection methods and select and apply one. \n",
    "\n",
    "My professor has provided the class a set of images. I will analyze these images and apply the HOG technique to detect faces. I will then draw a rectangle on each face of every image. Following this step, I will conclude by stitching the individual images together to produce a video.\n",
    "\n",
    "A special thanks to Adam Geitgey's [Machine Learning is Fun](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471) series on Medium. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Face detection is the process of identifying any human face in a given image or video. There are multiple techniques that pertain to an agent being able to detect a face in a given image. The methods are: knowledge-based, feature invariant approaches, template matching, and appearance based methods.\n",
    "\n",
    "The knowledge-based method is a rule-based method that has encoded in it knowledge about what constitutes a human face. The researcher is the one responsible for deriving these rules. A researcher can state that a face has two eyes, a nose and mouth. The difficulty arises in translating this knowledge into rules the system can comprehend. \n",
    "In feature invariant approaches, the aim is to find features that are present in an image even when the pose, viewpoint, or lighting conditions vary. The algorithm then utilizes these features to locate faces in an image. \n",
    "Template matching method is a technique that takes multiple standard patterns of a face and computes similarities between an input image and the stored patterns. The system is then able to both locate and detect a face in an image. Template matching is very simple to implement. Yet, one of the drawbacks of this approach is that it cannot deal with variations in pose, scale, and shape. \n",
    "\n",
    "Finally, appearance-based methods contrast heavily with template matching such that the templates in this method are learned from receiving multiple images as data. These techniques rely on principles of machine learning and statistics to generate the “templates”. Support vector machines, hidden Markov models, and deep convolutional neural networks are all examples of appearance-based methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    " For face detection I opted to go with the [Histogram of Oriented Gradients](http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf) (HOG) technique. \n",
    "\n",
    "The HOG technique is a feature descriptor utilized in computer vision\n",
    "for object detection in digital images. The principle, or theory, of histogram of oriented gradients is that objects in images can be described as the distribution of intensity gradients. HOG takes a pixel and determines which surrounding pixels are getting darker and replaces the analyzed pixel with a vector pointing towards the darkest surrounding pixel. \n",
    "\n",
    "![HOG applied to a face](example.png)\n",
    "\n",
    "In deciding to use this approach I compared HOG to another classic face detection technique known as Haar Cascades. I decided that while Haar Cascades may be faster and better suited for real-time applications, it provided too many false positives and HOG has better accuracy in recognizing faces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The goal is to be able to detect as many faces as possible. It is important to note beforehand that not all faces will be recognized immediately. This may be due to the orientation of the face as well as shading that prevents the HOG technique from detecting the face. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "![Before Face Detection](Pre_Face_Detection.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The main step is the use of a face detection algorithm to detect faces in an image. For this step I am utilizing the previously mentioned technique, Histogram of Oriented Gradients. I am implementing HOG using the [dlib](http://dlib.net) library. Students at another university tested both HOG and Haar Cascades with both OpenCV and dlib and they found that dlib's HOG implementation was far more accurate than the others. \n",
    "\n",
    "To get dlib's Python API installed I followed PyImageSearch's instructions:\n",
    "<http://www.pyimagesearch.com/2017/03/27/how-to-install-dlib/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets begin by first importing the numpy library for fast operations. We will also import the Dlib library which we will use for the HOG technique. Skimage will be utilized to read in the frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Create the HOG face detector using dlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we will begin the body of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89f5797a7489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Run HOG face detector on the image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# This will result in a set of bounding boxes on the faces.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdetected_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Clear previous overlays & add the image to the window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a window object to display the images\n",
    "win = dlib.image_window()\n",
    "\n",
    "with open(\"images/all_file.txt\") as file:\n",
    "    for line in file:\n",
    "        image_name = line\n",
    "        \n",
    "        # Load the image into an array.\n",
    "        image = io.imread(\"images/\" + image_name[:-1])\n",
    "        \n",
    "        # Run HOG face detector on the image. \n",
    "        # This will result in a set of bounding boxes on the faces.\n",
    "        detected_faces = face_detector(image, 1)\n",
    "        \n",
    "        # Clear previous overlays & add the image to the window\n",
    "        win.clear_overlay()\n",
    "        win.set_image(image)\n",
    "        \n",
    "        # For each face detected, add the overlay\n",
    "        for i, face_rect in enumerate(detected_faces):\n",
    "            win.add_overlay(detected_faces) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "One key addition to this program can be the addition of detecting faces even when they are turned or facing a different direction. \n",
    "\n",
    "In order to accomlish this one can use **face landmark estimation** in order to create a \"map\" of the human face. We create a set of points (landmarks) that represent common features on every face such as lips and eyes. A technique that can be used is [Kazemi & Sullivan's](http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf).\n",
    "\n",
    "![feature landmark extraction](fle.png) \n",
    "The 68 landmarks we will locate on every face. This image was created by Brandon Amos of CMU who works on OpenFace.\n",
    "\n",
    "After knowing where the facial features are located one can [shear](https://en.wikipedia.org/wiki/Shear_mapping), rotate, and scale the image in order to center the eyes and mouth as much as possible. \n",
    "\n",
    "A basic [affline transformation](https://en.wikipedia.org/wiki/Affine_transformation) can be utilized to perform these operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
